{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in raw data\n",
    "\n",
    "# For XRF, ignore repeats and standards\n",
    "xrf = pd.read_excel('raw/GAL-DV-21_XRF.xlsx',usecols='A:BB',index_col=0)\n",
    "\n",
    "# For ICPMS, ignnore repeats and standards\n",
    "icpms = pd.read_excel('raw/DV-21-ICPMS.xlsx',index_col=0,nrows=54)\n",
    "\n",
    "# Make directory for processed data\n",
    "os.makedirs('processed',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull normalized major elements from XRF and transpose to make samples index\n",
    "majors_norm = xrf.iloc[19:29,:].T\n",
    "\n",
    "# Remove extra space in majors columns\n",
    "new_cols = majors_norm.columns.str.replace(' ','')\n",
    "majors_norm_corr = majors_norm.copy()\n",
    "majors_norm_corr.columns = new_cols\n",
    "\n",
    "# Pull XRF trace elements and transpose\n",
    "xrf_trace = xrf.iloc[32:51,:].T\n",
    "\n",
    "# Remove extra space in XRF Trace columns\n",
    "new_cols = xrf_trace.columns.str[1:]\n",
    "xrf_trace_corr = xrf_trace.copy()\n",
    "xrf_trace_corr.columns = new_cols\n",
    "\n",
    "# Remove 'ppm' from ICPMS columns\n",
    "new_cols = icpms.columns.str[:-4]\n",
    "icpms_corr = icpms.copy()\n",
    "icpms_corr.columns  = new_cols\n",
    "\n",
    "# Remove XRF data duplicated by ICPMS\n",
    "common_cols = xrf_trace_corr.columns.intersection(icpms_corr.columns)\n",
    "xrf_trace_culled = xrf_trace_corr.drop(common_cols,axis=1)\n",
    "\n",
    "# Check what is in each file\n",
    "print(majors_norm_corr.columns)\n",
    "print(xrf_trace_culled.columns)\n",
    "print(icpms_corr.columns)\n",
    "print(majors_norm_corr.index.equals(xrf_trace_culled.index))\n",
    "print(xrf_trace_culled.index.equals(icpms_corr.index))\n",
    "\n",
    "# Combine into single dataframe\n",
    "data_organized = pd.concat([majors_norm_corr,xrf_trace_culled,icpms_corr],axis=1)\n",
    "print(data_organized.columns)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in metadata\n",
    "meta = pd.read_csv('metadata/gchm_smps_long.csv',index_col=0)\n",
    "\n",
    "# Isolate columns of interest\n",
    "meta_cols = ['Latitude','Longitude','Rock_Type','Period','S_Domain']\n",
    "\n",
    "# Create placeholder rows for 184 and 186 for now\n",
    "meta.loc['G22184',:] = 0\n",
    "meta.loc['G22186',:] = 0\n",
    "\n",
    "# Fix the misspelled Khaishi\n",
    "typo = meta[meta['S_Domain']=='Khashi'].index\n",
    "print(typo)\n",
    "meta.loc[typo,'S_Domain'] = 'Khaishi'\n",
    "\n",
    "# Isolate rows that were actually run\n",
    "meta_trimmed = meta.loc[data_organized.index,meta_cols]\n",
    "\n",
    "# Add metadata to main table\n",
    "data_final = data_organized.join(meta_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "data_final.to_csv('processed/data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-geoscripts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
